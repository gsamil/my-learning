# Backpropagation

At the heart of backpropagation is an expression for the partial derivative ∂C/∂w of the cost function C with respect to any weight w (or bias b) in the network. The expression tells us how quickly the cost changes when we change the weights and biases.

## References

- [How the backpropagation algorithm works](http://neuralnetworksanddeeplearning.com/chap2.html)
- [Backpropagation calculus | Chapter 4, Deep learning](https://youtu.be/tIeHLnjs5U8)
